{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f15331d1",
   "metadata": {},
   "source": [
    "+++\n",
    "title = \"Working with Scikit-Learn\"\n",
    "+++\n",
    "\n",
    "This guide goes through how to use this package with the Scikit-Learn package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e0a66",
   "metadata": {},
   "source": [
    "## Load the train and test datasets\n",
    "\n",
    "We'll first get the train and test splits for the `musk` dataset (completely unrelated to Elon Musk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ddc74d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already available at `temp/musk.npz`\n",
      "Data already available at `temp/musk.npz`\n",
      "The musk dataset is a classification task with 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tabben.datasets import OpenTabularDataset\n",
    "\n",
    "train = OpenTabularDataset('./temp', 'musk')  # train split by default\n",
    "test = OpenTabularDataset('./temp', 'musk', split='test')  # should only be used ONCE!\n",
    "\n",
    "print(f'The {train.name} dataset is a {train.task} task with {train.num_classes} classes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426ef090",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fulltrain, y_fulltrain = train.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bee214",
   "metadata": {},
   "source": [
    "In order to tune some hyperparameters, we'll need our own validation split (not the test set). We'll do an 80-20 split and stratify on the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26a1441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_fulltrain, y_fulltrain, \n",
    "    train_size=0.8, \n",
    "    stratify=y_fulltrain\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b0e7a5",
   "metadata": {},
   "source": [
    "## Create and train a model\n",
    "\n",
    "Next, we'll create a $k$-Nearest Neighbors model and train it on our train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ec249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faaeeaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174473e",
   "metadata": {},
   "source": [
    "And we'll evaluate it on our *validation* set, using a simple accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6cffe64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9837837837837838"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c45cad",
   "metadata": {},
   "source": [
    "## In a larger data processing pipeline\n",
    "\n",
    "However, it might be the case that we want to use a sklearn pipeline to do some data preprocessing like feature normalization, one-hot encoding, etc. or explore the effect of, say, turning continuous attributes into binary ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec52b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Binarizer, StandardScaler\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(with_std=False),\n",
    "    Binarizer(),\n",
    "    KNeighborsClassifier(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa8d036d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(with_std=False)),\n",
       "                ('binarizer', Binarizer()),\n",
       "                ('kneighborsclassifier', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4144984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9747747747747748"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab302f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This code was last run using the following package versions (if you're looking at the webpage which doesn't have the output, see the notebook for versions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04a44f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn: 1.0.1\n",
      "tabben: 0.0.6\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "packages = ['scikit-learn', 'tabben']\n",
    "\n",
    "for pkg in packages:\n",
    "    print(f'{pkg}: {version(pkg)}')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
