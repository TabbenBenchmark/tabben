{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5b2460",
   "metadata": {},
   "source": [
    "+++\n",
    "title = \"Working with Autogluon\"\n",
    "+++\n",
    "\n",
    "This guide goes through how to use this package with autogluon hyperparameter tuning package.\n",
    "\n",
    "## Load the train and test datasets\n",
    "\n",
    "First, we'll go ahead and grab the train and test sets for the [arcene](https://archive.ics.uci.edu/ml/datasets/Arcene) data set using the `tabben` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6de64a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already available at `data/arcene.npz`\n",
      "Data already available at `data/arcene.npz`\n"
     ]
    }
   ],
   "source": [
    "from tabben.datasets import OpenTabularDataset\n",
    "\n",
    "train_ds = OpenTabularDataset('./data/', 'arcene')\n",
    "test_ds = OpenTabularDataset('./data/', 'arcene', split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5d81f",
   "metadata": {},
   "source": [
    "This dataset has a large number of features, some of which are intentionally meaningless. (The attributes are not assigned to meaningful concepts either.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e359d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Attributes: 10000\n",
      "Attributes: ['0' '1' '2' ... '9997' '9998' '9999']\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Attributes: {train_ds.num_inputs}')\n",
    "print(f'Attributes: {train_ds.input_attributes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f7aaaa",
   "metadata": {},
   "source": [
    "For this dataset, we can get the metric functions that we should use (for consistency across everyone's runs) for evaluating on the test set. Autogluon will only use 1 metric (that it tests on its validation data set), so we just choose one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e220162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[binary auroc, ap score, binary mcc]\n"
     ]
    }
   ],
   "source": [
    "from tabben.evaluators.autogluon import get_metrics\n",
    "\n",
    "eval_metrics = get_metrics(train_ds.task, classes=train_ds.num_classes)\n",
    "\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec3fbd0",
   "metadata": {},
   "source": [
    "## Train the set of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b9e3a",
   "metadata": {},
   "source": [
    "Now we can use [autogluon](https://auto.gluon.ai/stable/index.html) to automatically train a large set of different models and evaluate on all of them. We'll use the `TabularPredictor` class from autogluon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6daf3149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    eval_metric=eval_metrics[0],\n",
    "    label=train_ds.output_attributes[0], \n",
    "    path='ag-covertype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600c0cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['medium_quality_faster_train']\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"ag-covertype/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    100\n",
      "Train Data Columns: 10000\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, -1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = -1\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (1) vs negative (-1) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6764.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.0 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 96 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 80): ['113', '143', '215', '227', '303', '416', '436', '453', '466', '557', '592', '993', '1544', '1902', '1956', '2109', '2199', '2213', '2219', '2349', '2409', '2482', '2520', '2583', '2589', '3020', '3273', '3278', '3390', '3562', '3657', '3714', '3729', '4200', '4234', '4238', '4328', '4448', '4621', '4637', '4649', '4676', '4843', '4846', '4847', '5034', '5313', '5372', '5415', '5610', '5626', '5735', '5756', '5778', '5940', '6309', '6346', '6866', '6995', '7057', '7091', '7181', '7218', '7295', '7449', '7809', '7929', '8081', '8188', '8189', '8588', '8704', '8840', '8867', '8878', '9165', '9356', '9538', '9895', '9913']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 9920 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 9824 | ['0', '1', '2', '3', '4', ...]\n",
      "\t\t('int', ['bool']) :   96 | ['277', '471', '519', '549', '652', ...]\n",
      "\t22.3s = Fit runtime\n",
      "\t9920 features in original data used to generate 9920 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.87 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 23.92s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'binary auroc'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 80, Val Rows: 20\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.7879\t = Validation score   (binary auroc)\n",
      "\t5.68s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7879\t = Validation score   (binary auroc)\n",
      "\t5.57s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "/home/tmthy/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.899\t = Validation score   (binary auroc)\n",
      "\t7.7s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "/home/tmthy/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9091\t = Validation score   (binary auroc)\n",
      "\t7.28s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7879\t = Validation score   (binary auroc)\n",
      "\t8.96s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9444\t = Validation score   (binary auroc)\n",
      "\t9.06s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tWarning: Exception caused CatBoost to fail during training... Skipping this model.\n",
      "\t\tcatboost/python-package/catboost/helpers.cpp:42: Traceback (most recent call last):\n",
      "  File \"_catboost.pyx\", line 1249, in _catboost._MetricEval\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/tabular/models/catboost/catboost_utils.py\", line 44, in evaluate\n",
      "    raise NotImplementedError('Custom Catboost Binary prob metrics are not supported by AutoGluon.')\n",
      "NotImplementedError: Custom Catboost Binary prob metrics are not supported by AutoGluon.\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"_catboost.pyx\", line 1249, in _catboost._MetricEval\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/tabular/models/catboost/catboost_utils.py\", line 44, in evaluate\n",
      "    raise NotImplementedError('Custom Catboost Binary prob metrics are not supported by AutoGluon.')\n",
      "NotImplementedError: Custom Catboost Binary prob metrics are not supported by AutoGluon.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 962, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 934, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 264, in _fit\n",
      "    self.model.fit(X, **fit_final_kwargs)\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/catboost/core.py\", line 4539, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/catboost/core.py\", line 1918, in _fit\n",
      "    self._train(\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/catboost/core.py\", line 1366, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4150, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4199, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/python-package/catboost/helpers.cpp:42: Traceback (most recent call last):\n",
      "  File \"_catboost.pyx\", line 1249, in _catboost._MetricEval\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/tabular/models/catboost/catboost_utils.py\", line 44, in evaluate\n",
      "    raise NotImplementedError('Custom Catboost Binary prob metrics are not supported by AutoGluon.')\n",
      "NotImplementedError: Custom Catboost Binary prob metrics are not supported by AutoGluon.\n",
      "\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.899\t = Validation score   (binary auroc)\n",
      "\t9.3s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.899\t = Validation score   (binary auroc)\n",
      "\t9.32s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "/home/tmthy/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:284: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[LABEL] = pd.concat([y, y_val], ignore_index=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric binary auroc is not supported by this model - using log_loss instead\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.7525\t = Validation score   (binary auroc)\n",
      "\t25.95s\t = Training   runtime\n",
      "\t3.81s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
      "\t\ttuple index out of range\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"_catboost.pyx\", line 1249, in _catboost._MetricEval\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/tabular/models/catboost/catboost_utils.py\", line 44, in evaluate\n",
      "    raise NotImplementedError('Custom Catboost Binary prob metrics are not supported by AutoGluon.')\n",
      "NotImplementedError: Custom Catboost Binary prob metrics are not supported by AutoGluon.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 962, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 934, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 130, in _fit\n",
      "    self.model.fit(\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1176, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/xgboost/training.py\", line 189, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/xgboost/training.py\", line 82, in _train_internal\n",
      "    if callbacks.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/xgboost/callback.py\", line 436, in after_iteration\n",
      "    self._update_history(score, epoch)\n",
      "  File \"/home/tmthy/.local/lib/python3.8/site-packages/xgboost/callback.py\", line 402, in _update_history\n",
      "    name, s = d[0], float(d[1])\n",
      "IndexError: tuple index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:17:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "/home/tmthy/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.8535\t = Validation score   (binary auroc)\n",
      "\t57.05s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9444\t = Validation score   (binary auroc)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 209.55s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag-covertype/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7f75fe477a60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(\n",
    "    train_ds.dataframe().head(300),  # artificially reduce the size of the dataset for faster demo\n",
    "    presets='medium_quality_faster_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3fae38",
   "metadata": {},
   "source": [
    "We can check to make sure that autogluon inferred the correct task (binary classification for this dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87457f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary\n",
      "('int', [])       : 9824 | ['0', '1', '2', '3', '4', ...]\n",
      "('int', ['bool']) :   96 | ['277', '471', '519', '549', '652', ...]\n"
     ]
    }
   ],
   "source": [
    "print(predictor.problem_type)\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b4cea",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddaf16f",
   "metadata": {},
   "source": [
    "Now, we're ready to evaluate our dataset. We can evaluate using autogluon's `leaderboard` method and supply our extra metrics that we want to compare by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc810465",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_ds.dataframe().drop(columns=test_ds.output_attributes)\n",
    "\n",
    "y_pred = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8280e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>ap score</th>\n",
       "      <th>binary mcc</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.769047</td>\n",
       "      <td>0.648372</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.060126</td>\n",
       "      <td>0.034189</td>\n",
       "      <td>5.569090</td>\n",
       "      <td>0.060126</td>\n",
       "      <td>0.034189</td>\n",
       "      <td>5.569090</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.769047</td>\n",
       "      <td>0.648372</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.104740</td>\n",
       "      <td>0.035959</td>\n",
       "      <td>5.677425</td>\n",
       "      <td>0.104740</td>\n",
       "      <td>0.035959</td>\n",
       "      <td>5.677425</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.713659</td>\n",
       "      <td>0.571913</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.112171</td>\n",
       "      <td>0.053485</td>\n",
       "      <td>8.963451</td>\n",
       "      <td>0.112171</td>\n",
       "      <td>0.053485</td>\n",
       "      <td>8.963451</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.699286</td>\n",
       "      <td>0.553152</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.108567</td>\n",
       "      <td>0.053596</td>\n",
       "      <td>9.056895</td>\n",
       "      <td>0.108567</td>\n",
       "      <td>0.053596</td>\n",
       "      <td>9.056895</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.699286</td>\n",
       "      <td>0.553152</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.113752</td>\n",
       "      <td>0.064668</td>\n",
       "      <td>9.544560</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.487665</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.758117</td>\n",
       "      <td>0.666585</td>\n",
       "      <td>0.495373</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.068197</td>\n",
       "      <td>0.055880</td>\n",
       "      <td>9.300864</td>\n",
       "      <td>0.068197</td>\n",
       "      <td>0.055880</td>\n",
       "      <td>9.300864</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.758117</td>\n",
       "      <td>0.666585</td>\n",
       "      <td>0.495373</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.089482</td>\n",
       "      <td>0.053756</td>\n",
       "      <td>9.319751</td>\n",
       "      <td>0.089482</td>\n",
       "      <td>0.053756</td>\n",
       "      <td>9.319751</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.754870</td>\n",
       "      <td>0.635900</td>\n",
       "      <td>0.472414</td>\n",
       "      <td>0.752525</td>\n",
       "      <td>7.353175</td>\n",
       "      <td>3.814076</td>\n",
       "      <td>25.952747</td>\n",
       "      <td>7.353175</td>\n",
       "      <td>3.814076</td>\n",
       "      <td>25.952747</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.742695</td>\n",
       "      <td>0.638891</td>\n",
       "      <td>0.457225</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.056324</td>\n",
       "      <td>0.034496</td>\n",
       "      <td>7.695588</td>\n",
       "      <td>0.056324</td>\n",
       "      <td>0.034496</td>\n",
       "      <td>7.695588</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.525556</td>\n",
       "      <td>0.241299</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.119512</td>\n",
       "      <td>0.035042</td>\n",
       "      <td>7.284855</td>\n",
       "      <td>0.119512</td>\n",
       "      <td>0.035042</td>\n",
       "      <td>7.284855</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.503237</td>\n",
       "      <td>0.189618</td>\n",
       "      <td>0.853535</td>\n",
       "      <td>0.053582</td>\n",
       "      <td>0.037282</td>\n",
       "      <td>57.050874</td>\n",
       "      <td>0.053582</td>\n",
       "      <td>0.037282</td>\n",
       "      <td>57.050874</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  ap score  binary mcc  score_val  \\\n",
       "0        KNeighborsDist    0.844156  0.769047    0.648372   0.787879   \n",
       "1        KNeighborsUnif    0.844156  0.769047    0.648372   0.787879   \n",
       "2      RandomForestGini    0.803571  0.713659    0.571913   0.787879   \n",
       "3      RandomForestEntr    0.794643  0.699286    0.553152   0.944444   \n",
       "4   WeightedEnsemble_L2    0.794643  0.699286    0.553152   0.944444   \n",
       "5        ExtraTreesGini    0.758117  0.666585    0.495373   0.898990   \n",
       "6        ExtraTreesEntr    0.758117  0.666585    0.495373   0.898990   \n",
       "7       NeuralNetFastAI    0.754870  0.635900    0.472414   0.752525   \n",
       "8            LightGBMXT    0.742695  0.638891    0.457225   0.898990   \n",
       "9              LightGBM    0.625000  0.525556    0.241299   0.909091   \n",
       "10        LightGBMLarge    0.600649  0.503237    0.189618   0.853535   \n",
       "\n",
       "    pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
       "0         0.060126       0.034189   5.569090                 0.060126   \n",
       "1         0.104740       0.035959   5.677425                 0.104740   \n",
       "2         0.112171       0.053485   8.963451                 0.112171   \n",
       "3         0.108567       0.053596   9.056895                 0.108567   \n",
       "4         0.113752       0.064668   9.544560                 0.005185   \n",
       "5         0.068197       0.055880   9.300864                 0.068197   \n",
       "6         0.089482       0.053756   9.319751                 0.089482   \n",
       "7         7.353175       3.814076  25.952747                 7.353175   \n",
       "8         0.056324       0.034496   7.695588                 0.056324   \n",
       "9         0.119512       0.035042   7.284855                 0.119512   \n",
       "10        0.053582       0.037282  57.050874                 0.053582   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.034189           5.569090            1       True   \n",
       "1                 0.035959           5.677425            1       True   \n",
       "2                 0.053485           8.963451            1       True   \n",
       "3                 0.053596           9.056895            1       True   \n",
       "4                 0.011071           0.487665            2       True   \n",
       "5                 0.055880           9.300864            1       True   \n",
       "6                 0.053756           9.319751            1       True   \n",
       "7                 3.814076          25.952747            1       True   \n",
       "8                 0.034496           7.695588            1       True   \n",
       "9                 0.035042           7.284855            1       True   \n",
       "10                0.037282          57.050874            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           2  \n",
       "1           1  \n",
       "2           5  \n",
       "3           6  \n",
       "4          11  \n",
       "5           7  \n",
       "6           8  \n",
       "7           9  \n",
       "8           3  \n",
       "9           4  \n",
       "10         10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_ds.dataframe(), silent=True, extra_metrics=eval_metrics[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b3773",
   "metadata": {},
   "source": [
    "(If you're looking at the leaderboard in the notebook, the 'score_test' column represents the auroc metric that was passed to the `TabularPredictor` constructor.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03148b1e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This code was last run with the following versions (if you're looking at the no-output webpage, see the notebook in the repository for versions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a265cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autogluon: 0.3.1\n",
      "tabben: 0.0.6\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "packages = ['autogluon', 'tabben']\n",
    "\n",
    "for pkg in packages:\n",
    "    print(f'{pkg}: {version(pkg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee286c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
